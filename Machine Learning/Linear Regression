# -*- coding: utf-8 -*-
"""HW2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1phu9xeWQNo8hdWX6Lg2e1-B9tp-b49fn

Q3
"""

# Commented out IPython magic to ensure Python compatibility.
# Implement a function for learning the parameters of a linear model for a given tranining data 
# with user-specified learning rate n and number of epochs T.
# %matplotlib inline
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
T = 5000
n = 0.001
test = 0.33
random = 42

from sklearn import datasets, linear_model
# Load the diabetes dataset
diabetes = datasets.load_diabetes()
X = diabetes.data
y = diabetes.target
samp, natt = X.shape
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, random_state=random)
print("Training data is {0:.3f}".format(1-test), "of all data and test data is", test, "of all")

regr = linear_model.LinearRegression()
regr.fit(X_train,y_train)

y_pred = regr.predict(X_test)
RSS = np.mean((y_pred-y_test)**2)/(np.std(y_test)**2) 
Rsq = 1-RSS
print("RSS per sample = {0:f}".format(RSS)) 
print("R^2 calculated by sklearn = {0:f}".format(Rsq))

X_train = np.insert(X_train, 0, 1, axis = 1)
X_test = np.insert(X_test, 0, 1, axis = 1)

def norm(w):
  return 0.5*(y_train - X_train.dot(w)).dot(y - X_train.dot(w))
wk = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
def gradient(w):
  return X_train.T.dot(X_train.dot(w)-y_train)

def gradient_descent(init, steps, grad):
  w0 = [init]
  for step in steps:
    w0.append(w0[-1] - step * grad(w0[-1]))
  return w0

print("Learning rate is",n,"\nNumber of epochs is", T)
wout = gradient_descent(wk,[n]*T,gradient)
print("Parameters are:\n",wout[-1])

yp = X_test.dot(wout[-1])
RSS1 = np.mean((yp-y_test)**2)/(np.std(y_test)**2) 
Rsq1 = 1-RSS1
print("RSS per sample = {0:f}".format(RSS1)) 
print("R^2 calculated by me = {0:f}".format(Rsq1))

"""Q4"""

import pandas as pd
names =[
't',
'q1', 'q2', 'q3',
'dq1', 'dq2', 'dq3',
'I1', 'I2', 'I3',
'eps21', 'eps22', 'eps31', 'eps32',
'ddq1', 'ddq2', 'ddq3'
]
# Time (secs)
# Joint angle
# Joint velocity
# Motor current (A)
# Strain measurements
# Joint accelerations
df = pd.read_csv('exp_train.csv', header=None,sep=',', names=names, index_col=0)
df.head(6)

df.columns.to_list()
# Labels y: A vector of all the samples in the ‘I2’ column
import numpy as np
df1 = df.dropna()
y = np.array(df1['I2'])
print("Lables y is:\n",y)
# Data X: A matrix of the data with the columns: [‘q2’,‘dq2’,‘eps21’,‘eps22’,‘eps31’,‘eps32’,‘ddq2’]
XT = np.array([df1['q2'],df1['dq2'],df1['eps21'],df1['eps22'],df1['eps31'],df1['eps32'],df1['ddq2']])
X = np.transpose(XT)
print("Data X is:\n",X)

from sklearn import linear_model
from sklearn.metrics import mean_squared_error
samp, natt = X.shape

regr = linear_model.LinearRegression()
regr.fit(X,y)
regr.intercept_

regr.coef_

y_pred = regr.predict(X)
RSS = np.mean((y_pred-y)**2)/(np.std(y)**2) 
print("RSS per sample = {0:f}".format(RSS))
MSE = mean_squared_error(y, y_pred) 
print("MSE of training data = {0:f}".format(MSE))

df = pd.read_csv('exp_test.csv', header=None,sep=',', names=names, index_col=0)
df.columns.to_list()
# Labels y: A vector of all the samples in the ‘I2’ column
df1 = df.dropna()
y = np.array(df1['I2'])
# Data X: A matrix of the data with the columns: [‘q2’,‘dq2’,‘eps21’,‘eps22’,‘eps31’,‘eps32’,‘ddq2’]
XT = np.array([df1['q2'],df1['dq2'],df1['eps21'],df1['eps22'],df1['eps31'],df1['eps32'],df1['ddq2']])
X = np.transpose(XT)
y_pred = regr.predict(X)
RSS = np.mean((y_pred-y)**2)/(np.std(y)**2) 
print("RSS per sample = {0:f}".format(RSS))
MSE = mean_squared_error(y, y_pred) 
print("MSE of test data = {0:f}".format(MSE))
